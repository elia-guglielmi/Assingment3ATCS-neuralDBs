{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eaced97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb07d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampling dataset creation\n",
    "df=pd.read_csv(r\"D:\\uni\\AdvancedTopics\\Assignment3\\DB\\card_games\\cards.csv\")\n",
    "df=df.sample(20,random_state=42)\n",
    "df_rule=pd.read_csv(r\"D:\\uni\\AdvancedTopics\\Assignment3\\DB\\card_games\\ruling.csv\")\n",
    "result = df_rule[df_rule['uuid'].isin(df['uuid'])]\n",
    "users=pd.read_csv(r\"DB\\codebase\\users.csv\")\n",
    "users=users.sample(20,random_state=42)\n",
    "#users.to_csv(\"DB/codebase/users20sample.csv\")\n",
    "posts=pd.read_csv(r\"DB\\codebase\\posts.csv\")\n",
    "posts=posts.sample(20,random_state=42)\n",
    "#posts.to_csv(\"DB/codebase/posts20sample.csv\")\n",
    "#df.to_csv(\"DB/card_games/cards_sample20.csv\")\n",
    "#result.to_csv(\"DB/card_games/ruling_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a05aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict, Union, Optional,Any\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv('GROQ_API_KEY')\n",
    "model_name=os.getenv('MODEL_NAME')\n",
    "# Initialize Groq client\n",
    "client = Groq(api_key=groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ca859c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================== GENERIC UDFs zero shot ======================\n",
    "\n",
    "def analyze_sentiment(text: str) -> float:\n",
    "    \"\"\"Sentiment Analysis: Returns score between -1 (negative) and 1 (positive)\"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Analyze sentiment of this text. Return ONLY a float between -1 (negative) and 1 (positive).\"\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": text\n",
    "        }],\n",
    "        model=model_name, \n",
    "        temperature=0.0,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    return float(chat_completion.choices[0].message.content)\n",
    "\n",
    "def align_to_schema(data: Dict, domain: str) -> List[Dict]:\n",
    "    prompt = f\"\"\"Convert this table column mapping to Schema.org/{domain} property names:\n",
    "    For each column name in the input data, provide the most appropriate Schema.org property name.\n",
    "    The input data is: {data}\n",
    "    \n",
    "    Return ONLY a valid JSON array where each element is an object with:\n",
    "    - the original column name as key\n",
    "    - the corresponding Schema.org property name as value\n",
    "    \n",
    "    Example output format:\n",
    "    {{\n",
    "      \"name\": \"name\",\n",
    "      \"flavorText\": \"description\",\n",
    "      \"text\": \"text\",\n",
    "      \"type\": \"additionalType\"\n",
    "    }}\"\"\"\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt + \"\\n\\nJSON output required:\"\n",
    "        }],\n",
    "        model=model_name,\n",
    "        temperature=0.0,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    # Get the response and convert it to a list of mappings\n",
    "    result = json.loads(chat_completion.choices[0].message.content)\n",
    "    return result\n",
    "\n",
    "def classify_entity(text: str, classes: List[str]) -> str:\n",
    "    \"\"\"Entity Classification: Categorizes text into predefined classes\"\"\"\n",
    "    prompt = f\"\"\"Classify this text into one of {classes}:\n",
    "    {text}\n",
    "    Return ONLY the class name.\"\"\"\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=model_name,\n",
    "        temperature=0.0,\n",
    "        max_tokens=20\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content.strip()\n",
    "\n",
    "def summarize(text: str, max_length: int = 50) -> str:\n",
    "    \"\"\"Summarization: Condenses text to specified length\"\"\"\n",
    "    prompt = f\"\"\"Summarize this in under {max_length} characters:\n",
    "    {text}\n",
    "    Summary:\"\"\"\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=model_name,\n",
    "        temperature=0.0,\n",
    "        max_tokens=max_length\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content.strip()\n",
    "\n",
    "def extract_entities(text: str, entity_types: List[str]) -> List[str]:\n",
    "    prompt = f\"\"\"Extract ALL {entity_types} from this text:\n",
    "    \"{text}\"\n",
    "    Return ONLY a Python-style list like [\"item1\", \"item2\"] with no other text.\"\"\"\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=model_name,\n",
    "        temperature=0.0,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        return eval(chat_completion.choices[0].message.content)\n",
    "    except:\n",
    "        return []\n",
    "    try:\n",
    "        # Handle both direct string response and JSON object\n",
    "        response = chat_completion.choices[0].message.content\n",
    "        if isinstance(response, str):\n",
    "            return eval(response)\n",
    "        elif isinstance(response, dict):\n",
    "            return list(response.values())[0]  # Assumes first value is the list\n",
    "    except:\n",
    "        return []  # Fallback to empty list on parsing failure\n",
    "\n",
    "def impute_missing(\n",
    "    row: Dict[str, Any],\n",
    "    column_to_impute: str,\n",
    "    context_columns: List[str],\n",
    "    type_hint: Optional[str] = None,\n",
    "    id_columns: Optional[List[str]] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generic missing value imputation using specified context columns.\n",
    "    \n",
    "    Args:\n",
    "        row: Input data row as dictionary\n",
    "        column_to_impute: Key containing missing value\n",
    "        context_columns: List of columns to use for context\n",
    "        type_hint: Expected data type (\"numeric\", \"date\", \"boolean\", \"text\")\n",
    "        id_columns: Columns to exclude from context (even if in context_columns)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with imputed value (or original if imputation fails)\n",
    "    \"\"\"\n",
    "    result_row=row.copy()\n",
    "    # Return early if no imputation needed\n",
    "    if row.get(column_to_impute) not in [None, \"NULL\", \"\", \"null\"] and not pd.isna(row.get(column_to_impute)):\n",
    "        return row[column_to_impute]\n",
    "    \n",
    "    # Filter context columns\n",
    "    id_columns = id_columns or []\n",
    "    available_context = [\n",
    "        (k, str(row[k])) for k in context_columns \n",
    "        if k in row and k != column_to_impute \n",
    "        and row[k] is not None and k not in id_columns\n",
    "    ]\n",
    "    \n",
    "    # Build context string\n",
    "    context_str = \"\\n\".join(f\"{k}: {v}\" for k, v in available_context)\n",
    "    if not context_str:\n",
    "        return row[column_to_impute]  # No context available\n",
    "    \n",
    "    # Determine type hint\n",
    "    type_instruction = \"\"\n",
    "    if type_hint:\n",
    "        type_map = {\n",
    "            \"numeric\": \"Return only a number without symbols\",\n",
    "            \"date\": \"Use YYYY-MM-DD format\",\n",
    "            \"boolean\": \"Return 'true' or 'false'\",\n",
    "            \"text\": \"Return a string without quotes\"\n",
    "        }\n",
    "        type_instruction = f\"\\nIMPORTANT: {type_map.get(type_hint, '')}\"\n",
    "    \n",
    "    prompt = f\"\"\"Impute missing value for '{column_to_impute}' based on this context:\n",
    "    {context_str}\n",
    "    {type_instruction}\n",
    "    Return ONLY the raw value with no additional text or formatting.\"\"\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=model_name,\n",
    "        temperature=0.0,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    \n",
    "    result_row[column_to_impute] = chat_completion.choices[0].message.content.strip()\n",
    "    return result_row\n",
    "\n",
    "\n",
    "def augment_schema(row: Dict, new_field: str, prompt: str) -> Dict:\n",
    "    \"\"\"Schema Augmentation: Adds new derived field\"\"\"\n",
    "    user_prompt = f\"\"\"{prompt}\n",
    "    Data: {row}\n",
    "    Return ONLY the value for {new_field}.\"\"\"\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "        model=model_name,\n",
    "        temperature=0.0,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    row[new_field] = chat_completion.choices[0].message.content.strip()\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4140c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================== GENERIC UDFs few shot ======================\n",
    "def analyze_sentiment(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Sentiment Analysis with few-shot learning: \n",
    "    Returns score between -1 (negative) and 1 (positive)\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    \n",
    "    # Few-shot examples to improve sentiment analysis accuracy\n",
    "    few_shot_examples = [\n",
    "        {\"text\": \"I absolutely love this product!\", \"sentiment\": 0.9},\n",
    "        {\"text\": \"This is the worst experience ever.\", \"sentiment\": -0.8},\n",
    "        {\"text\": \"It's okay, nothing special.\", \"sentiment\": 0.1},\n",
    "        {\"text\": \"Incredibly disappointed and frustrated.\", \"sentiment\": -0.7},\n",
    "        {\"text\": \"Amazing service and great quality!\", \"sentiment\": 0.95}\n",
    "    ]\n",
    "    \n",
    "    # Construct messages with few-shot examples\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Analyze sentiment of text. Return ONLY a float between -1 (negative) and 1 (positive).\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add few-shot examples\n",
    "    for example in few_shot_examples:\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": example[\"text\"]\n",
    "        })\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": str(example[\"sentiment\"])\n",
    "        })\n",
    "    \n",
    "    # Add current text to analyze\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": text\n",
    "    })\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model_name,  \n",
    "        temperature=0.0, \n",
    "        max_tokens=10\n",
    "    )\n",
    "    return float(chat_completion.choices[0].message.content)\n",
    "\n",
    "def align_to_schema(data: Dict, domain: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Schema alignment with few-shot examples\n",
    "    Converts table column mapping to Schema.org property names\n",
    "    \"\"\"\n",
    "    # Few-shot examples for different domains\n",
    "    few_shot_examples = {\n",
    "        \"Product\": [\n",
    "            {\n",
    "                \"input\": {\"name\": \"iPhone 12\", \"price\": 799, \"color\": \"Blue\"},\n",
    "                \"output\": {\n",
    "                    \"name\": \"name\",\n",
    "                    \"price\": \"offers.price\",\n",
    "                    \"color\": \"color\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"input\": {\"brand\": \"Apple\", \"description\": \"Smartphone\", \"weight\": \"164g\"},\n",
    "                \"output\": {\n",
    "                    \"brand\": \"brand\",\n",
    "                    \"description\": \"description\",\n",
    "                    \"weight\": \"weight\"\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"Person\": [\n",
    "            {\n",
    "                \"input\": {\"first_name\": \"John\", \"birth_year\": 1990, \"job_title\": \"Engineer\"},\n",
    "                \"output\": {\n",
    "                    \"first_name\": \"givenName\",\n",
    "                    \"birth_year\": \"birthDate\",\n",
    "                    \"job_title\": \"jobTitle\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Select few-shot examples for the specific domain\n",
    "    domain_examples = few_shot_examples.get(domain, few_shot_examples[\"Product\"])\n",
    "    \n",
    "    # Construct messages with few-shot examples\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Convert table column mapping to Schema.org/{domain} property names. Return ONLY a valid JSON mapping.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add few-shot examples\n",
    "    for example in domain_examples:\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Input data: {json.dumps(example['input'])}\"\n",
    "        })\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": json.dumps(example['output'])\n",
    "        })\n",
    "    \n",
    "    # Add current data to map\n",
    "    messages.append({\n",
    "        \"role\": \"user\", \n",
    "        \"content\": f\"Input data: {json.dumps(data)}\\n\\nJSON output required:\"\n",
    "    })\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model_name, \n",
    "        temperature=0.0, \n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    # Get the response and convert it to a list of mappings\n",
    "    result = json.loads(chat_completion.choices[0].message.content)\n",
    "    return result\n",
    "\n",
    "def classify_entity(text: str, classes: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Entity Classification with few-shot learning\n",
    "    Categorizes text into predefined classes\n",
    "    \"\"\"\n",
    "    # Few-shot examples for different classification scenarios\n",
    "    few_shot_examples = [\n",
    "        {\"text\": \"Breaking news about tech innovation\", \"class\": \"Technology\"},\n",
    "        {\"text\": \"Quarterly financial results announced\", \"class\": \"Finance\"},\n",
    "        {\"text\": \"New medical breakthrough in cancer research\", \"class\": \"Science\"},\n",
    "        {\"text\": \"Political debate heats up before election\", \"class\": \"Politics\"},\n",
    "        {\"text\": \"Concert tickets sold out in minutes\", \"class\": \"Entertainment\"}\n",
    "    ]\n",
    "    \n",
    "    # Construct messages with few-shot examples\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Classify text into one of {classes}. Return ONLY the class name.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add few-shot examples\n",
    "    for example in few_shot_examples:\n",
    "        if example[\"class\"] in classes:\n",
    "            messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": example[\"text\"]\n",
    "            })\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": example[\"class\"]\n",
    "            })\n",
    "    \n",
    "    # Add current text to classify\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Classify this text into one of {classes}: {text}\"\n",
    "    })\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model_name, \n",
    "        temperature=0.0, \n",
    "        max_tokens=20\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content.strip()\n",
    "\n",
    "def summarize(text: str, max_length: int = 50) -> str:\n",
    "    \"\"\"\n",
    "    Summarization with few-shot learning\n",
    "    Condenses text to specified length\n",
    "    \"\"\"\n",
    "    # Few-shot examples of summarization\n",
    "    few_shot_examples = [\n",
    "        {\n",
    "            \"text\": \"The quick brown fox jumps over the lazy dog. It was a beautiful day in the forest with sunlight streaming through the trees.\",\n",
    "            \"summary\": \"Fox jumps over lazy dog on a beautiful day.\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Machine learning is a complex field of artificial intelligence that involves training algorithms to learn from and make predictions or decisions based on data.\",\n",
    "            \"summary\": \"ML is AI that trains algorithms to learn from data.\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Climate change is causing significant global environmental challenges, including rising sea levels, more frequent extreme weather events, and disruptions to ecosystems.\",\n",
    "            \"summary\": \"Climate change threatens environment with sea rise and extreme weather.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Construct messages with few-shot examples\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Summarize text in under {max_length} characters, capturing key points.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add few-shot examples\n",
    "    for example in few_shot_examples:\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": example[\"text\"]\n",
    "        })\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": example[\"summary\"]\n",
    "        })\n",
    "    \n",
    "    # Add current text to summarize\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Summarize this in under {max_length} characters: {text}\"\n",
    "    })\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model_name, \n",
    "        temperature=0.0, \n",
    "        max_tokens=max_length\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content.strip()\n",
    "\n",
    "def extract_entities(text: str, entity_types: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Entity Extraction with few-shot learning\n",
    "    Extracts specified entity types from text\n",
    "    \"\"\"\n",
    "    # Few-shot examples of entity extraction\n",
    "    few_shot_examples = [\n",
    "        {\n",
    "            \"text\": \"Apple Inc. was founded by Steve Jobs in Cupertino, California in 1976.\",\n",
    "            \"entities\": {\n",
    "                \"organizations\": [\"Apple Inc.\"],\n",
    "                \"persons\": [\"Steve Jobs\"],\n",
    "                \"locations\": [\"Cupertino\", \"California\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"The World Health Organization reported a breakthrough in medical research in Geneva, Switzerland.\",\n",
    "            \"entities\": {\n",
    "                \"organizations\": [\"World Health Organization\"],\n",
    "                \"locations\": [\"Geneva\", \"Switzerland\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Construct messages with few-shot examples\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Extract ALL {entity_types} from the text. Return ONLY a Python-style list.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add few-shot examples\n",
    "    for example in few_shot_examples:\n",
    "        for entity_type, entities in example[\"entities\"].items():\n",
    "            if entity_type in entity_types:\n",
    "                messages.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": example[\"text\"]\n",
    "                })\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": str(entities)\n",
    "                })\n",
    "    \n",
    "    # Add current text to extract entities from\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Extract ALL {entity_types} from this text: \\\"{text}\\\"\"\n",
    "    })\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model_name, \n",
    "        temperature=0.0, \n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Safely evaluate the response\n",
    "        response = chat_completion.choices[0].message.content.strip()\n",
    "        return eval(response)\n",
    "    except:\n",
    "        try:\n",
    "            # Handle both direct string response and JSON object \n",
    "            if isinstance(response, str):\n",
    "                return eval(response)\n",
    "            elif isinstance(response, dict):\n",
    "                return list(response.values())[0]  # Assumes first value is the list\n",
    "        except:\n",
    "            return []  # Fallback to empty list on parsing failure\n",
    "\n",
    "def impute_missing(\n",
    "    row: Dict[str, Any], \n",
    "    column_to_impute: str, \n",
    "    context_columns: List[str], \n",
    "    type_hint: Optional[str] = None, \n",
    "    id_columns: Optional[List[str]] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generic missing value imputation with few-shot learning\n",
    "    Uses specified context columns and provides type-specific guidance\n",
    "    \"\"\"\n",
    "    # Few-shot examples for different imputation scenarios\n",
    "    few_shot_examples = {\n",
    "        \"numeric\": [\n",
    "            {\n",
    "                \"context\": \"age: 35, height: None, weight: 75\",\n",
    "                \"imputed_value\": \"180\"\n",
    "            },\n",
    "            {\n",
    "                \"context\": \"salary: 50000, bonus: None, years_experience: 5\",\n",
    "                \"imputed_value\": \"7500\"\n",
    "            }\n",
    "        ],\n",
    "        \"date\": [\n",
    "            {\n",
    "                \"context\": \"hire_date: 2020-01-15, term_start: None, last_promotion: 2022-06-01\",\n",
    "                \"imputed_value\": \"2020-07-01\"\n",
    "            }\n",
    "        ],\n",
    "        \"text\": [\n",
    "            {\n",
    "                \"context\": \"product_name: Smartphone X, description: None, category: Electronics\",\n",
    "                \"imputed_value\": \"High-performance smartphone with advanced features\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    result_row = row.copy()\n",
    "    \n",
    "    # Return early if no imputation needed\n",
    "    if row.get(column_to_impute) not in [None, \"NULL\", \"\", \"null\"] and not pd.isna(row.get(column_to_impute)):\n",
    "        return row[column_to_impute]\n",
    "    \n",
    "    # Filter context columns\n",
    "    id_columns = id_columns or []\n",
    "    available_context = [\n",
    "        (k, str(row[k])) for k in context_columns \n",
    "        if k in row and k != column_to_impute \n",
    "        and row[k] is not None and k not in id_columns\n",
    "    ]\n",
    "    \n",
    "    # Build context string\n",
    "    context_str = \"\\n\".join(f\"{k}: {v}\" for k, v in available_context)\n",
    "    if not context_str:\n",
    "        return row[column_to_impute]  # No context available\n",
    "    \n",
    "    # Construct messages with few-shot examples\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Impute missing value for '{column_to_impute}' based on context.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add few-shot examples based on type hint\n",
    "    if type_hint and type_hint in few_shot_examples:\n",
    "        for example in few_shot_examples[type_hint]:\n",
    "            messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context: {example['context']}\"\n",
    "            })\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": example[\"imputed_value\"]\n",
    "            })\n",
    "    \n",
    "    # Determine type instruction\n",
    "    type_instruction = \"\"\n",
    "    if type_hint:\n",
    "        type_map = {\n",
    "            \"numeric\": \"Return only a number without symbols\",\n",
    "            \"date\": \"Use YYYY-MM-DD format\",\n",
    "            \"boolean\": \"Return 'true' or 'false'\",\n",
    "            \"text\": \"Return a string without quotes\"\n",
    "        }\n",
    "        type_instruction = f\"\\nIMPORTANT: {type_map.get(type_hint, '')}\"\n",
    "    \n",
    "    # Add current context\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Context: {context_str}{type_instruction}\"\n",
    "    })\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model_name, \n",
    "        temperature=0.0, \n",
    "        max_tokens=50\n",
    "    )\n",
    "    \n",
    "    result_row[column_to_impute] = chat_completion.choices[0].message.content.strip()\n",
    "    return result_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b398e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "cards_df = pd.read_csv(\"DB/card_games/cards_sample20.csv\")\n",
    "rulings_df = pd.read_csv(\"DB/card_games/ruling_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49739819",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts=pd.read_csv(r\"DB/codebase/posts20sample.csv\")\n",
    "users=pd.read_csv(r\"DB/codebase/users20sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26389a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Civic Wayfinder', 'Ostiary Thrull']\n"
     ]
    }
   ],
   "source": [
    "def test_sentiment_analysis_001(cards: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Test Case ID: entity_classification_001\n",
    "    Calculates the sentiment score on cards' flavourtext and returns the negative ones\n",
    "    \"Which cards have flavor text with negative sentiment?\"\n",
    "    equivalent SQL:\n",
    "    SELECT name\n",
    "    FROM cards\n",
    "    WHERE flavorText IS NOT NULL\n",
    "    AND analyze_sentiment(flavorText) < 0;\n",
    "    \"\"\"\n",
    "    negative_cards = []\n",
    "    for _, card in cards.iterrows():\n",
    "        if pd.notna(card['flavorText']):\n",
    "            sentiment = analyze_sentiment(card['flavorText'])\n",
    "            if sentiment < 0:  # Negative sentiment\n",
    "                negative_cards.append(card['name'])\n",
    "    return negative_cards\n",
    "\n",
    "print(test_sentiment_analysis_001(cards_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff003e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2269']\n"
     ]
    }
   ],
   "source": [
    "def test_sentiment_analysis_002(users: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Test Case ID: sentiment_analysis_002\n",
    "    Finds users with AboutMe descriptions having a negative sentiment (score below -0.5)\n",
    "    \"Find users with AboutMe descriptions having a negative sentiment (score below -0.5)\"\n",
    "    equivalent SQL:\n",
    "    SELECT Id\n",
    "    FROM users\n",
    "    WHERE AboutMe IS NOT NULL\n",
    "    AND analyze_sentiment(AboutMe) < -0.5;\n",
    "    \"\"\"\n",
    "    negative_users = []\n",
    "    for _, user in users.iterrows():\n",
    "        if pd.notna(user['AboutMe']):\n",
    "            sentiment = analyze_sentiment(user['AboutMe'])\n",
    "            if sentiment < -0.5:  # Highly negative sentiment\n",
    "                negative_users.append(str(user['Id']))\n",
    "    return negative_users\n",
    "\n",
    "print(test_sentiment_analysis_002(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88612c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def test_sentiment_analysis_003(posts: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Test Case ID: sentiment_analysis_003\n",
    "    Identifies posts with highly positive sentiment (score > 0.7)\n",
    "    \"Identify posts with highly positive sentiment (score > 0.7)\"\n",
    "    equivalent SQL:\n",
    "    SELECT Id\n",
    "    FROM posts\n",
    "    WHERE Body IS NOT NULL\n",
    "    AND analyze_sentiment(Body) > 0.7;\n",
    "    \"\"\"\n",
    "    positive_posts = []\n",
    "    for _, post in posts.iterrows():\n",
    "        if pd.notna(post['Body']):\n",
    "            sentiment = analyze_sentiment(post['Body'])\n",
    "            if sentiment > 0.7:  # Highly positive sentiment\n",
    "                positive_posts.append(str(post['Id']))\n",
    "    return positive_posts\n",
    "print(test_sentiment_analysis_003(posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4ce5cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['41203', '52599', '7547', '31765']\n"
     ]
    }
   ],
   "source": [
    "def test_sentiment_analysis_004(users: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Test Case ID: sentiment_analysis_004\n",
    "    Finds user AboutMe descriptions with neutral sentiment (between -0.2 and 0.2)\n",
    "    \"Find user AboutMe descriptions with neutral sentiment (between -0.2 and 0.2)\"\n",
    "    equivalent SQL:\n",
    "    SELECT Id\n",
    "    FROM users\n",
    "    WHERE AboutMe IS NOT NULL\n",
    "    AND analyze_sentiment(AboutMe) BETWEEN -0.2 AND 0.2;\n",
    "    \"\"\"\n",
    "    neutral_users = []\n",
    "    for _, user in users.iterrows():\n",
    "        if pd.notna(user['AboutMe']):\n",
    "            sentiment = analyze_sentiment(user['AboutMe'])\n",
    "            if -0.2 <= sentiment <= 0.2:  # Neutral sentiment\n",
    "                neutral_users.append(str(user['Id']))\n",
    "    return neutral_users\n",
    "print(test_sentiment_analysis_004(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026daf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def test_sentiment_analysis_005(posts: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Test Case ID: sentiment_analysis_005\n",
    "    Identifies posts with slightly negative sentiment below 0\n",
    "    \"Identify posts with slightly negative sentiment below 0\"\n",
    "    equivalent SQL:\n",
    "    SELECT Id\n",
    "    FROM posts\n",
    "    WHERE Body IS NOT NULL\n",
    "    AND analyze_sentiment(Body) < -0.5;\n",
    "    \"\"\"\n",
    "    negative_posts = []\n",
    "    for _, post in posts.iterrows():\n",
    "        if pd.notna(post['Body']):\n",
    "            sentiment = analyze_sentiment(post['Body'])\n",
    "            if sentiment < 0:  # Highly negative sentiment\n",
    "                negative_posts.append(str(post['Id']))\n",
    "    return negative_posts\n",
    "print(test_sentiment_analysis_005(posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ced7d43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def test_sentiment_analysis_006(rulings: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Test Case ID: sentiment_analysis_006\n",
    "    Finds rulings with sentiment outside the neutral range (-0.2 to 0.2)\n",
    "    \"Find rulings with sentiment outside the neutral range (-0.2 to 0.2)\"\n",
    "    equivalent SQL:\n",
    "    SELECT id\n",
    "    FROM rulings\n",
    "    WHERE text IS NOT NULL\n",
    "    AND (analyze_sentiment(text) < -0.2 OR analyze_sentiment(text) > 0.2);\n",
    "    \"\"\"\n",
    "    distinctive_sentiment_rulings = []\n",
    "    for _, ruling in rulings.iterrows():\n",
    "        if pd.notna(ruling['text']):\n",
    "            sentiment = analyze_sentiment(ruling['text'])\n",
    "            if sentiment < -0.2 or sentiment > 0.2:  # Outside neutral range\n",
    "                distinctive_sentiment_rulings.append(str(ruling['id']))\n",
    "    return distinctive_sentiment_rulings\n",
    "print(test_sentiment_analysis_006(rulings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423e6b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control\n"
     ]
    }
   ],
   "source": [
    "def test_entity_classification_001(cards: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Test Case ID: entity_classification_001\n",
    "    Classifies the archetype of 'Twilight Prophet' based on text using\n",
    "    \"What is the archetype of Twilight Prophet?\"\n",
    "    equivalent SQL:\n",
    "    SELECT \n",
    "    'Twilight Prophet' AS card_name,\n",
    "    classify_entity(\n",
    "        text, \n",
    "        ARRAY['Aggro', 'Control', 'Combo']  -- Array of possible archetypes\n",
    "    ) AS archetype\n",
    "    FROM cards\n",
    "    WHERE name = 'Twilight Prophet'\n",
    "    LIMIT 1; \n",
    "    \"\"\"\n",
    "    # Get the specific card data\n",
    "    card = cards[cards['name'] == 'Twilight Prophet'].iloc[0]\n",
    "    archetype=classify_entity(card['text'],[\"Aggro\",\"Control\",\"Combo\"])\n",
    "    return archetype\n",
    "\n",
    "print(test_entity_classification_001(cards_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63e3debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Crested Sunmare', 'Ancestral Memories']\n"
     ]
    }
   ],
   "source": [
    "def test_entity_recognition_001(cards: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Test Case ID: entity_recognition_001\n",
    "    Identifies people or creature entities in a text and returns all the cards that present identified entities in their flavour text\n",
    "    Which cards mention creatures or people in their flavor text?\n",
    "    equivalent SQL:\n",
    "    SELECT DISTINCT name\n",
    "    FROM cards\n",
    "    WHERE flavorText IS NOT NULL\n",
    "    AND extract_entities(flavorText, ARRAY['PERSON','CREATURE']::text[]) IS NOT NULL;\n",
    "    \n",
    "    \"\"\"\n",
    "    entity_cards = []\n",
    "    for _, card in cards.iterrows():\n",
    "        if pd.notna(card['flavorText']):\n",
    "            entities = extract_entities(card['flavorText'], [\"PERSON\",\"CREATURE\"])\n",
    "            if entities:  # Found mentions of people/creatures\n",
    "                entity_cards.append(card['name'])\n",
    "    return entity_cards\n",
    "\n",
    "print(test_entity_recognition_001(cards_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd052f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Lady Sun', 'mapped_properties': {'name': 'name', 'flavorText': 'description', 'text': 'description'}}]\n"
     ]
    }
   ],
   "source": [
    "def test_schema_alignment_001(cards: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Test Case ID: schema_alignment_001  \n",
    "    Map card properties to Schema.org types.\n",
    "    equivalent SQL:\n",
    "    SELECT \n",
    "        name,\n",
    "        align_to_schema(\n",
    "            JSON_BUILD_OBJECT(\n",
    "                'name', name,\n",
    "                'flavorText', flavorText,\n",
    "                'text', text,\n",
    "                'type', type\n",
    "            ),\n",
    "            'Game'\n",
    "        ) AS mapped_properties\n",
    "    FROM cards\n",
    "    WHERE name = 'Lady Sun';\n",
    "      \n",
    "    \"\"\"\n",
    "    aligned = []\n",
    "    for _, card in cards.iterrows():\n",
    "        if card['name'] == \"Lady Sun\":  # From test case\n",
    "            mapped = align_to_schema({\n",
    "                \"name\": card['name'],\n",
    "                \"flavorText\": card['flavorText'],\n",
    "                \"text\": card['text'],\n",
    "                \"type\": card['type']\n",
    "            }, \"Game\")\n",
    "            aligned.append({\n",
    "                \"name\": card['name'],\n",
    "                \"mapped_properties\": mapped\n",
    "            })\n",
    "    return aligned\n",
    "print(test_schema_alignment_001(cards_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be693abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Esper Sojourners', 'imputed_toughness': '3'}, {'name': 'Dream Stalker', 'imputed_toughness': '3'}, {'name': 'Civic Wayfinder', 'imputed_toughness': '3'}]\n"
     ]
    }
   ],
   "source": [
    "def test_imputation_missing_001(cards: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Test Case ID: imputation_missing_001\n",
    "    Calls the llm to try and fill a specific column value based on external knowledge and the other columns values \n",
    "    \"Fill in the missing toughness value of creatures based on other card fields.\"\n",
    "    equivalent SQL:\n",
    "    WITH creature_cards AS (\n",
    "    SELECT *\n",
    "    FROM cards\n",
    "    WHERE LOWER(type) LIKE '%creature%'\n",
    "    ),\n",
    "    cards_to_impute AS (\n",
    "    SELECT *\n",
    "    FROM creature_cards\n",
    "    WHERE toughness IS NULL \n",
    "        OR toughness = '' \n",
    "        OR LOWER(toughness) = 'null'\n",
    "    )\n",
    "    SELECT \n",
    "    name,\n",
    "    impute_missing(\n",
    "        JSON_BUILD_OBJECT(\n",
    "        'name', name,\n",
    "        'type', type,\n",
    "        'power', power,\n",
    "        'text', text\n",
    "        ),\n",
    "        'toughness',\n",
    "        ARRAY['name', 'type', 'power', 'text'],\n",
    "        'numeric'\n",
    "    ) AS imputed_toughness\n",
    "    FROM cards_to_impute;\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get the creature type cards\n",
    "    creature_cards = cards_df[cards_df['type'].str.contains('Creature', case=False, na=False)].copy()\n",
    "    # List of cards to modify \n",
    "    cards_to_update = [\"Civic Wayfinder\", \"Dream Stalker\", \"Esper Sojourners\"]\n",
    "\n",
    "    # Update toughness to None/NULL for those specific cards\n",
    "    creature_cards.loc[creature_cards['name'].isin(cards_to_update), 'toughness'] = None\n",
    "    imputed_cards=[]\n",
    "    creature_cards=creature_cards.to_dict('records')\n",
    "    for card in creature_cards:\n",
    "        if pd.isna(card[\"toughness\"]) or card[\"toughness\"] in [None, \"NULL\", \"\", \"null\"]:\n",
    "            imputed_cards.append({\"name\":card[\"name\"],\"imputed_toughness\":impute_missing(\n",
    "        row=card,\n",
    "        column_to_impute=\"toughness\",\n",
    "        context_columns=[\"name\", \"type\", \"power\", \"text\"],\n",
    "        type_hint=\"numeric\")[\"toughness\"]})\n",
    "    return(imputed_cards)\n",
    "    \n",
    "print(test_imputation_missing_001(cards_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7ab784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Esper Sojourners', 'summary': 'Cycling interacts with ability effects, not spell effects.'}]\n"
     ]
    }
   ],
   "source": [
    "def test_summarization_001(cards: pd.DataFrame, rulings: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Test Case ID: summarization_001\n",
    "    Calls the llm to summarize a text\n",
    "    \"Summarize rulings for 'Esper Sojourners'.\"\n",
    "    equivalent SQL:\n",
    "    WITH card_uuid AS (\n",
    "    SELECT uuid\n",
    "    FROM cards\n",
    "    WHERE name = 'Esper Sojourners'\n",
    "    ),\n",
    "    combined_rulings AS (\n",
    "    SELECT \n",
    "        c.name,\n",
    "        STRING_AGG(r.text, E'\\n' ORDER BY r.text) AS rulings_text\n",
    "    FROM card_uuid cu\n",
    "    JOIN cards c ON c.uuid = cu.uuid\n",
    "    JOIN rulings r ON r.uuid = cu.uuid\n",
    "    GROUP BY c.name\n",
    "    )\n",
    "    SELECT \n",
    "    name,\n",
    "    summarize(rulings_text, 100) AS summary\n",
    "    FROM combined_rulings;\n",
    "    \n",
    "    \"\"\"\n",
    "    summaries = []\n",
    "    card_name = \"Esper Sojourners\"\n",
    "    card_uuid = cards[cards['name'] == card_name]['uuid'].iloc[0]\n",
    "    card_rulings = rulings[rulings['uuid'] == card_uuid]\n",
    "    \n",
    "    if not card_rulings.empty:\n",
    "        combined_rulings = \"\\n\".join(card_rulings['text'])\n",
    "        summary = summarize(combined_rulings, 100)\n",
    "        summaries.append({\n",
    "            \"name\": card_name,\n",
    "            \"summary\": summary\n",
    "        })\n",
    "    return summaries\n",
    "\n",
    "print(test_summarization_001(cards_df,rulings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce39f429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blizzard Brawl', 'Crested Sunmare', 'Ancestral Memories']\n"
     ]
    }
   ],
   "source": [
    "def test_classification_002(cards: pd.DataFrame, rulings: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Test Case ID: classification_002\n",
    "    Identifies cards with rulings classified as \"damage_prevention\" \n",
    "    \"Which cards have rulings that mention 'damage prevention'?\"\n",
    "    equivalent SQL:\n",
    "    SELECT DISTINCT c.name\n",
    "    FROM rulings r\n",
    "    JOIN cards c ON r.uuid = c.uuid\n",
    "    WHERE classify_entity(r.text, ARRAY['damage_prevention', 'other']) = 'damage_prevention';\n",
    "    \n",
    "    \"\"\"\n",
    "    damage_prevention_cards = []\n",
    "    \n",
    "    for _, ruling in rulings.iterrows():\n",
    "        # Classify the ruling text\n",
    "        classification = classify_entity(\n",
    "            text=ruling['text'],\n",
    "            classes=[\"damage_prevention\", \"other\"],\n",
    "        )\n",
    "        \n",
    "        if classification == \"damage_prevention\":\n",
    "            card = cards[cards['uuid'] == ruling['uuid']].iloc[0]\n",
    "            damage_prevention_cards.append(card['name'])\n",
    "    \n",
    "    return list(set(damage_prevention_cards))\n",
    "print(test_classification_002(cards_df,rulings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b54f6ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'Artifact Creature — Horse', 'buff_count': 0, 'total_cards': 1}, {'type': 'Artifact Creature — Vedalken Wizard', 'buff_count': 0, 'total_cards': 1}, {'type': 'Artifact — Equipment', 'buff_count': 0, 'total_cards': 1}, {'type': 'Creature — Elf Druid Warrior', 'buff_count': 0, 'total_cards': 1}, {'type': 'Creature — Horse', 'buff_count': 0, 'total_cards': 1}, {'type': 'Creature — Illusion', 'buff_count': 0, 'total_cards': 1}, {'type': 'Creature — Merfolk Soldier', 'buff_count': 0, 'total_cards': 1}, {'type': 'Creature — Thrull', 'buff_count': 0, 'total_cards': 1}, {'type': 'Creature — Vampire Cleric', 'buff_count': 0, 'total_cards': 1}, {'type': 'Enchantment', 'buff_count': 2, 'total_cards': 2}, {'type': 'Instant', 'buff_count': 0, 'total_cards': 2}, {'type': 'Land', 'buff_count': 0, 'total_cards': 3}, {'type': 'Legendary Creature — Human Advisor', 'buff_count': 0, 'total_cards': 1}, {'type': 'Snow Sorcery', 'buff_count': 0, 'total_cards': 1}, {'type': 'Sorcery', 'buff_count': 0, 'total_cards': 2}]\n"
     ]
    }
   ],
   "source": [
    "def test_entity_recognition_002(cards: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Test Case ID: entity_recognition_002\n",
    "    call llm to analyze the text to identify cards that give a buff and count how many identified cards for each type\n",
    "    How many cards of each type have text that inplies giving a buff?\n",
    "    equivalent SQL:\n",
    "    SELECT \n",
    "        type,\n",
    "        COUNT(CASE WHEN extract_entities(text, ARRAY['buff', 'stat increase']) IS NOT NULL THEN 1 END) AS buff_count,\n",
    "        COUNT(*) AS total_cards\n",
    "    FROM cards\n",
    "    WHERE text IS NOT NULL\n",
    "    GROUP BY type;\n",
    "    \n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Group by card type and process each group\n",
    "    for card_type, group in cards.groupby('type'):\n",
    "        buff_count = 0\n",
    "        \n",
    "        for text in group['text'].dropna():  # Skip NaN values\n",
    "            extracted = extract_entities(text, [\"buff\", \"stat increase\"])\n",
    "            if extracted:\n",
    "                buff_count += 1\n",
    "                \n",
    "        \n",
    "        results.append({\n",
    "            \"type\": card_type,\n",
    "            \"buff_count\": buff_count,\n",
    "            \"total_cards\": len(group)\n",
    "        })\n",
    "    return results\n",
    "\n",
    "print(test_entity_recognition_002(cards_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "083437fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Crested Sunmare', 'summary': \"Crested Sunmare's ability triggers if you gained life this turn, not during end step.\", 'sentiment': 'positive'}, {'name': 'Helm of the Gods', 'summary': \"You control Aura on opponent's permanent.\", 'sentiment': 'positive'}]\n"
     ]
    }
   ],
   "source": [
    "def test_analyze_sentiment_summarize_001(cards: pd.DataFrame, rulings: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Test Case ID: analyze_sentiment_summarize_001\n",
    "    calls an llm to assing a sentiment score to flavour text of the cards,\n",
    "    than takes the cards with positive score(>0.5)\n",
    "    and finds those wid rulings, finally calls again the llm to produce\n",
    "    a summary of said rulings\n",
    "    \"Cards with positive flavor text sentiment and complex rulings.\"\n",
    "    equivalent SQL:\n",
    "    SELECT\n",
    "    c.name,\n",
    "    summarize(string_agg(r.text, E'\\n'), 100) AS summary,\n",
    "    'positive' AS sentiment\n",
    "    FROM cards c\n",
    "    JOIN rulings r ON c.uuid = r.uuid\n",
    "    WHERE c.flavorText IS NOT NULL\n",
    "    AND analyze_sentiment(c.flavorText) > 0.5\n",
    "    GROUP BY c.name;\n",
    "    \n",
    "    \"\"\"\n",
    "    complex_cards = []\n",
    "    for _, card in cards.iterrows():\n",
    "        if pd.notna(card['flavorText']):\n",
    "            sentiment = analyze_sentiment(card['flavorText'])\n",
    "            if sentiment > 0.5:\n",
    "                card_rulings = rulings[rulings['uuid'] == card['uuid']]\n",
    "                if not card_rulings.empty:\n",
    "                    combined_rulings = \"\\n\".join(card_rulings['text'])\n",
    "                    summary = summarize(combined_rulings, 100)\n",
    "                    complex_cards.append({\n",
    "                        \"name\": card['name'],\n",
    "                        \"summary\": summary,\n",
    "                        \"sentiment\": \"positive\"\n",
    "                    })\n",
    "    return complex_cards\n",
    "print(test_analyze_sentiment_summarize_001(cards_df,rulings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29979584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Crested Sunmare', 'imputed_rarity': 'Rare', 'archetype': 'aggro'}, {'name': 'Dream Stalker', 'imputed_rarity': 'Rare', 'archetype': 'control'}, {'name': 'Ostiary Thrull', 'imputed_rarity': 'Rare', 'archetype': 'control'}]\n"
     ]
    }
   ],
   "source": [
    "def test_entity_impute_classify_001(cards: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Test Case ID: analyze_sentiment_summarize_001\n",
    "    For creature cards with missing rarity:\n",
    "    finds the cards with missing rarity  values, calls the llm to predict it and\n",
    "    classify archetype\n",
    "    \"For creature cards with missing rarity, predict the rarity based on their stats and classify them by their gameplay archetype.\"\n",
    "    equivalent SQL:\n",
    "    WITH missing_rarity_creatures AS (\n",
    "    SELECT *\n",
    "    FROM cards\n",
    "    WHERE LOWER(type) LIKE '%creature%'\n",
    "        AND rarity IS NULL\n",
    "    ),\n",
    "    processed_cards AS (\n",
    "    SELECT\n",
    "        name,\n",
    "        impute_missing(\n",
    "        JSON_BUILD_OBJECT(\n",
    "            'name', name,\n",
    "            'type', type,\n",
    "            'power', power,\n",
    "            'toughness', toughness,\n",
    "            'text', text,\n",
    "            'manaCost', manaCost\n",
    "        ),\n",
    "        'rarity',\n",
    "        ARRAY['name', 'type', 'power', 'toughness', 'text', 'manaCost'],\n",
    "        'text'\n",
    "        )->>'rarity' AS imputed_rarity,\n",
    "        classify_entity(\n",
    "        CONCAT(\n",
    "            'Card: ', name, '\\n',\n",
    "            'Stats: ', power, '/', toughness, ' (MV: ', manaCost, ')\\n',\n",
    "            'Text: ', COALESCE(text, '')\n",
    "        ),\n",
    "        ARRAY['aggro', 'control', 'combo', 'midrange', 'hybrid']\n",
    "        ) AS archetype\n",
    "    FROM missing_rarity_creatures\n",
    "    )\n",
    "    SELECT\n",
    "    name,\n",
    "    imputed_rarity,\n",
    "    LOWER(archetype) AS archetype\n",
    "    FROM processed_cards;\n",
    "    \n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Force rarity=None for our test cases\n",
    "    cards.loc[cards['name'].isin([\n",
    "        \"Dream Stalker\", \n",
    "        \"Ostiary Thrull\", \n",
    "        \"Crested Sunmare\"\n",
    "    ]), 'rarity'] = None\n",
    "    \n",
    "    # Filter creatures with missing rarity\n",
    "    creatures = cards[\n",
    "        (cards['type'].str.contains('Creature', case=False, na=False)) & \n",
    "        (cards['rarity'].isna())\n",
    "    ].copy()\n",
    "    \n",
    "    for _, card in creatures.iterrows():\n",
    "        # Convert card data to dict for UDF processing\n",
    "        card_data = card.to_dict()\n",
    "        \n",
    "        # Impute missing rarity\n",
    "        imputed_card = impute_missing(\n",
    "            row=card_data,\n",
    "            column_to_impute=\"rarity\",\n",
    "            context_columns=[\"name\", \"type\", \"power\", \"toughness\", \"text\", \"manaCost\"],\n",
    "            type_hint=\"text\"\n",
    "        )\n",
    "        \n",
    "        #Classify archetype\n",
    "        archetype = classify_entity(\n",
    "            text=f\"\"\"\n",
    "            Card: {card['name']}\n",
    "            Stats: {card['power']}/{card['toughness']} (MV: {card['manaCost']})\n",
    "            Text: {card['text']}\n",
    "            \"\"\",\n",
    "            classes=[\"aggro\", \"control\", \"combo\", \"midrange\", \"hybrid\"],\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            \"name\": card['name'],\n",
    "            \"imputed_rarity\": imputed_card[\"rarity\"],\n",
    "            \"archetype\": archetype.lower()\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "print(test_entity_impute_classify_001(cards_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d4d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c395d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIRD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
